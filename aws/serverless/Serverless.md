기본적으로 서버리스 기술은 클라우드 공급자가 모든 관리를와 가용성과 용량 등을 책임지기 때문에 기본 인프라 및 플랫폼 관리에 대한 걱정을 안해도 됨. 즉 인프라적인 부분은 aws같은 클라우드 공급자가 알아서 해주기 때문에 사용자는 코드만 짜면 됨.

# 5.1 ALB에서 람다 함수를 호출하도록 구성
``` bash
시작하기 앞서 퍼블릿 서브넷 두개가 필요해서 vpc를 생성하고 subnet을 인터넷 게이트웨이에 연결
그 다음 ec2 탭에 가서 ALB를 생성했고 대상 그룹(필수)도 같이 생성하고 람다 함수를 추후에 넣는 옵션을 선택
-> http 요청에 응답할 람다 함수를 만들어준 다음 해당 람다 함수를 대상 그룹으로 등록 -> alb 리스너의 규칙에 /function 경로에 대해 내가 만든 람다 함수로 가도록 설정!!
근데 연결이 안돼서 찾아봤더니 람다함수와 alb는 vpc에 같이 존재해야해서 람다함수 역할엘 vpc 정책을 추가해주고 alb에 등록했던 vpc를 람다 함수에 연결 후 테스트 했더니 응답이 왔습니다!!(보안그룹도 80번 포트에 대해 받을 수 있도록 인바운드 규칙을 조금 수정했어여)
```
alb를 이용해서 특정 경로에 대해 람다 함수를 호출할 수 있고 이렇게 하다보면 단일 로드 밸런서에서 여러 경로와 대상을 가질 수 있겓 됨.(람다 말고도 ec2나 컨테이너로도 대상 선정이 가능)

# 5.2 람다 계층을 사용한 라이브러리 패키징
```
람다 계층은 라이브러리 나 기타 종속성을 패키징할 수 있도록 제공. .zip파일로 계층을 생성할 수 있고 s3에 저장된 파일도 가능. 
즉, 기본적으로 제공해주는 python 런타임 이외에 라이브러리를 추가하거나 사용자 정의 런타임을 사용할 수 있음.
해당 예제에서는 requests 모듈을 해당 람다 함수에 계층으로 추가해주는 과정! 이때 zip파일로 계층을 생성
```

# 5.3 람다 함수 스케쥴링
```
aws EventBridge 서비스를  통해 일정을 만들 수 있음
일정은 일회성인지 반복인지 정할 수 있고 반복 일정의 경우엔 cron기반과 rate기반이 있음.
대상 선택 api 경우엔 여러개가 있는데 container도 있고 lambda도 존재하고 다양하게 존재.
재시도 횟수랑 이런것도 추가적으로 정할 수 있고 DLQ라고 대상에 성공적으로 전달되지 못했을 경우 사용하는 SQS 대기열!
추가적으로 권한에는 역할 만들어주면 끝! 이후에는 람다의 로그를 확인하기 위해 람다함수의 모니터링 탭에서 cloud wathc 로그 보는 탭을 선택해서 확인!!
```

# 5.4 람다 함수에서 EFS 파일 시스템 사용
``` bash
서버리스 컴퓨팅과 서버리스 영구 저장소를 사용하면 컴퓨팅 및 스토리지 운영 오버헤드를 크게 줄일 수 있음.
일단 먼저 vpc 셋팅을 진행하고 efs를 하나 만들고 vpc를 내가 만든 것과 연결함.
액세스 포인트를 하나 생성해주고 nfs의 보안그룹은 vpc의 서브넷 보안그룹을 수정하면 되고 람다 함수의 보안 그룹 tcp 2049포트에 대한 허용을 해줌.
람다 함수의 경우엔 vpc에 대한 권한을 추가해줌. 그 다음 람다 함수의 vpc를 편집하고 그다음 파일 시스템을 추가해주면 끝!
python 코드를 test해주면 잘 연결됐는지 확인될 수 있음!
```